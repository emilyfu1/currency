{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec2d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DOTS data from csv file\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import country_converter as coco\n",
    "import os\n",
    "from dotenv import dotenv_values, find_dotenv\n",
    "\n",
    "# this looks for your configuration file and then reads it as a dictionary\n",
    "config = dotenv_values(find_dotenv())\n",
    "\n",
    "# set path using the dictionary key for which one you want\n",
    "path_cleandata = os.path.abspath(config[\"CLEANDATA\"]) + '\\\\'\n",
    "path_rawdata = os.path.abspath(config[\"RAWDATA\"]) + '\\\\'\n",
    "\n",
    "cc = coco.CountryConverter()\n",
    "\n",
    "# Loading DOTS data from csv file\n",
    "dots = pd.read_csv(path_rawdata+'IMF_DOTS.csv',low_memory=False)\n",
    "tmpdots = dots.copy()\n",
    "\n",
    "alldots = tmpdots.copy()\n",
    "alldots = alldots[['Country Code', 'Counterpart Country Code', \n",
    "                'Indicator Code', 'Time Period', 'Value']]\n",
    "\n",
    "# Renaming columns\n",
    "alldots.columns = ['CountryCode','PartnerCode','type','year','value']\n",
    "\n",
    "# Convert 'type' to a category data type\n",
    "alldots['type'] = alldots.type.astype('category')\n",
    "\n",
    "# Rename categories for type column\n",
    "alldots['type'] = alldots['type'].cat.rename_categories(\n",
    "    {'TMG_CIF_USD': 'imports_cif', 'TBG_USD': 'tradebalance', \n",
    "     'TXG_FOB_USD': 'exports_fob', 'TMG_FOB_USD': 'imports_fob'})\n",
    "\n",
    "alldots.dropna()\n",
    "\n",
    "# Load dataframe with IMF country code in 'IMF' colum and iso3 country code in 'iso3' column\n",
    "country_code_mapping = pd.read_csv(path_rawdata+'Country_iso_codes.csv')\n",
    "country_code_mapping = country_code_mapping[['iso3','IMF']]  # CHANGE #1 ABOVE MADE HERE!!!!\n",
    "\n",
    "# Make a dictionary out of the dataframe\n",
    "dict = country_code_mapping.set_index('IMF').to_dict()['iso3']\n",
    "\n",
    "# Replace IMF country codes in CountryCode and PartnerCode columns\n",
    "# by corresponding ISO3 country codes\n",
    "alldots['CountryCode']= alldots['CountryCode'].map(dict)\n",
    "alldots['PartnerCode']= alldots['PartnerCode'].map(dict)\n",
    "\n",
    "# Rename contry code columns\n",
    "alldots.rename(columns = {'CountryCode': 'iso3_o', 'PartnerCode': 'iso3_d'}, inplace = True)\n",
    "\n",
    "# Drop missing values\n",
    "dotssub = alldots[['iso3_o','iso3_d','type','year','value']].dropna()\n",
    "\n",
    "# Create euro area aggregate for DOTS corresponding to WDI's EMU \n",
    "# First, get year of adoption of euro for each country\n",
    "euro = pd.read_csv(path_rawdata+'Euro_Yield_Dates.csv', encoding='latin-1')\n",
    "euro['Currency'] = None\n",
    "euro['EntryDate'] = pd.DatetimeIndex(pd.to_datetime(euro['Date'], format='%d/%m/%Y')).year\n",
    "euro['Date'] = None\n",
    "euro['iso2'] = euro['Code'].str[:2]\n",
    "euro['iso3'] = cc.pandas_convert(series=euro['iso2'], to='ISO3')\n",
    "euro = euro[['iso3','EntryDate']] # euro dataframe is only left with 2 columns, country code and entry year\n",
    "\n",
    "tmpdots = dotssub.copy()\n",
    "\n",
    "# create a euro dummy for if the o or d is in the euro in that year\n",
    "tmpeuro = euro.copy()\n",
    "tmpeuro.rename(columns = {'iso3': 'iso3_o', 'EntryDate': 'EntryDate_o'}, inplace=True)\n",
    "tmpeuro.sort_values(['iso3_o'])\n",
    "tmpdots.sort_values(['iso3_o'])\n",
    "\n",
    "tmpdots = pd.merge(left=tmpdots, right=tmpeuro, on='iso3_o', how='left')\n",
    "\n",
    "tmpeuro = euro.copy()\n",
    "tmpeuro.rename(columns = {'iso3': 'iso3_d', 'EntryDate': 'EntryDate_d'}, inplace=True)\n",
    "\n",
    "tmpdots = pd.merge(left=tmpdots, right=tmpeuro, on='iso3_d', how='left')\n",
    "\n",
    "tmpdots = tmpdots[tmpdots['iso3_d'].notna()]\n",
    "tmpdots = tmpdots[tmpdots['iso3_o'].notna()]\n",
    "\n",
    "tmpdots['ineuro_o'] = tmpdots['EntryDate_o'] <= tmpdots['year']\n",
    "tmpdots['ineuro_d'] = tmpdots['EntryDate_d'] <= tmpdots['year']\n",
    "\n",
    "tmpdots[['ineuro_o', 'ineuro_d']] = tmpdots[['ineuro_o', 'ineuro_d']].fillna(False)\n",
    "\n",
    "# Make tmpdots the full dataframe with in euro dummy for o and d countries\n",
    "tmpdots = tmpdots[['iso3_o', 'iso3_d', 'year', 'ineuro_o', 'ineuro_d', 'type', 'value']]\n",
    "\n",
    "# Create new dots dataframe with only observations where d countries are not in euro\n",
    "# This is going to represent the trade flows between origin anywhere and destination\n",
    "# not in eurozone\n",
    "noeuro_d = tmpdots.loc[tmpdots['ineuro_d'] == False]\n",
    "# sum imports resp. exports by countries o in the euro zone in a year\n",
    "euro_o = noeuro_d.loc[noeuro_d['ineuro_o'].eq(1)]\\\n",
    "        .groupby(['iso3_d','type','year'], as_index=False)['value'].sum()\n",
    "euro_o['iso3_o']='EUR'\n",
    "euro_o = euro_o[['iso3_o','iso3_d','type','year','value']]\n",
    "\n",
    "# Now create dots dataframe with only observations where o countries are not in euro\n",
    "noeuro_o = tmpdots.loc[tmpdots['ineuro_o'] == False]\n",
    "# sum imports resp. exports by countries d in the euro zone in a year\n",
    "euro_d = noeuro_o.loc[noeuro_o['ineuro_d'].eq(1)]\\\n",
    "        .groupby(['iso3_o','type','year'], as_index=False)['value'].sum()\n",
    "euro_d['iso3_d']='EUR'\n",
    "euro_d = euro_d[['iso3_o','iso3_d','type','year','value']]\n",
    "\n",
    "# Combine two dataframes to create new dataframe that has all trade flows between\n",
    "# euro zone and non-euro zone countries\n",
    "euro = pd.concat([euro_o, euro_d])\n",
    "euro.sort_values(['iso3_o','iso3_d','year'])\n",
    "\n",
    "alldots = pd.concat([dotssub, euro])\n",
    "alldots.sort_values(['iso3_o','iso3_d','year'])\n",
    "\n",
    "# Need to check with Nick that what is achieved with setkey in r is achieved with sort_values here\n",
    "\n",
    "# Drop trade balance data\n",
    "alldots = alldots[alldots['type'].isin(['imports_cif','imports_fob','exports_fob'])]\n",
    "# Reshape from long to wide format\n",
    "dotswide = alldots.pivot_table(index=['iso3_o','iso3_d','year'],columns='type',values='value').reset_index()\\\n",
    "            .rename_axis(None, axis=1)\n",
    "           \n",
    "# Make clean bilateral dataset\n",
    "tmp1 = dotswide[['iso3_o','iso3_d','year','imports_cif','exports_fob']]\n",
    "tmp1 = tmp1.rename(columns = {'imports_cif': 'imports_o', 'exports_fob': 'exports_o'})\n",
    "tmp2 = dotswide[['iso3_o','iso3_d','year','imports_cif','exports_fob']]\n",
    "tmp2 = tmp2.rename(columns = {'iso3_o': 'iso3_d','iso3_d': 'iso3_o','imports_cif': 'imports_d', 'exports_fob': 'exports_d'})\n",
    "\n",
    "tmp = pd.merge(left=tmp1, right=tmp2, on=['iso3_o','iso3_d','year'], how='outer')\n",
    "\n",
    "tmp.sort_values(by=['iso3_o','iso3_d','year'])\n",
    "\n",
    "# Replace missing values for exports_o with imports_d (etc) and vice versa\n",
    "tmp['exports_o'].fillna(tmp['imports_d'])\n",
    "tmp['exports_d'].fillna(tmp['imports_o'])\n",
    "tmp['imports_o'].fillna(tmp['exports_d'])\n",
    "tmp['imports_d'].fillna(tmp['exports_o'])\n",
    "\n",
    "# Save\n",
    "tmp.to_pickle(path_cleandata+'IMF_DOTS.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e137a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

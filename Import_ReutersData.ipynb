{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e30fe5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import xlrd\n",
    "import pickle\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import calendar\n",
    "import country_converter as coco\n",
    "import os\n",
    "from dotenv import dotenv_values, find_dotenv\n",
    "\n",
    "# this looks for your configuration file and then reads it as a dictionary\n",
    "config = dotenv_values(find_dotenv())\n",
    "\n",
    "# set path using the dictionary key for which one you want\n",
    "path_cleandata = os.path.abspath(config[\"CLEANDATA\"]) + '\\\\'\n",
    "path_rawdata = os.path.abspath(config[\"RAWDATA\"]) + '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa3b879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Barclays forward rates (using actual dataset)\n",
    "#FX_Fwd_temp = pd.read_excel(path_rawdata+'Datastream & Barclays - Spots & 1M Forwards.xlsx', sheet_name='RFV FX Fwd', skiprows=0)\n",
    "FX_Fwd_temp = pd.read_excel(path_rawdata+'Datastream & Barclays - Spots & 1M Forwards.xlsx', sheet_name='RFV FX Fwd Outright', skiprows=0)\n",
    "FX_Fwd_temp['Date'] =pd.to_datetime(FX_Fwd_temp['Date'])\n",
    "\n",
    "# Convert column names to country names (Nick comment: I don't like the hard coded method of the fake data)\n",
    "colDetails =  pd.read_excel(path_rawdata+'Exchange Rates - Datastream Codes.xlsx', sheet_name='RFV FX Fwd Outright Codes', skiprows=0)\n",
    "colDetails = colDetails[['Symbol','Country']]\n",
    "colDetails = colDetails[colDetails['Symbol'].isin(FX_Fwd_temp.columns)]\n",
    "\n",
    "# fix couple of outlier labels\n",
    "colDetails.loc[colDetails['Country']=='Euro','Country']='Euro Area'\n",
    "colDetails.loc[colDetails['Country']=='Euro (inverse)','Country']='Euro Area (INVERSE)'\n",
    "colDetails.loc[colDetails['Country']=='Hong Kong','Country']='CHINA HONG KONG'\n",
    "colDetails.loc[colDetails['Country']=='Estonia','Country']='ESTONIAN'\n",
    "colDetails.loc[colDetails['Country']=='Jordan','Country']='JORDANIA'\n",
    "colDetails.loc[colDetails['Country']=='Serbia','Country']='SERBIA AND MONTENEGRO'\n",
    "\n",
    "# make upper case\n",
    "colDetails.loc[:,'Country']=colDetails['Country'].str.upper()\n",
    "\n",
    "# drop duplicate Japan, Switzerland and Russia series \n",
    "FX_Fwd_temp = FX_Fwd_temp.drop(columns=['TDJP21M','TDCH21M','TDRU21M','TDRU11M'])\n",
    "\n",
    "# make all upper case\n",
    "FX_Fwd_temp =FX_Fwd_temp.rename(columns = colDetails.set_index('Symbol')['Country'])\n",
    "\n",
    "for nam in FX_Fwd_temp.columns:\n",
    "    if '(INVERSE)' in nam:\n",
    "        # remove inverse from name\n",
    "        newNam = nam.replace(' (INVERSE)','')\n",
    "        FX_Fwd_temp=FX_Fwd_temp.rename(columns={nam:newNam})\n",
    "        \n",
    "        # invert series\n",
    "        FX_Fwd_temp.loc[:,newNam]=1.0/FX_Fwd_temp.loc[:,newNam]\n",
    "        \n",
    "        \n",
    "# now replace country with IMF code\n",
    "IMF_codes = pd.read_excel(path_rawdata+'IMF_codes.xlsx',header=None,names=['Country', 'IMF Code'])\n",
    "FX_Fwd_temp = FX_Fwd_temp.rename(columns = IMF_codes.set_index('Country')['IMF Code'].astype('str'))\n",
    "\n",
    "\n",
    "# Now repeat the same with the spot data!\n",
    "FX_Spot_temp = pd.read_excel(path_rawdata+'Datastream & Barclays - Spots & 1M Forwards.xlsx', sheet_name='RFV FX Spot', skiprows=0)\n",
    "\n",
    "\n",
    "# Convert column names to country names (Nick comment: I don't like the hard coded method of the fake data)\n",
    "colDetails =  pd.read_excel(path_rawdata+'Exchange Rates - Datastream Codes.xlsx', sheet_name='RFV Spot Codes', skiprows=0)\n",
    "colDetails = colDetails[['Symbol','Country']]\n",
    "colDetails = colDetails[colDetails['Symbol'].isin(FX_Spot_temp.columns)]\n",
    "\n",
    "# fix couple of outlier labels\n",
    "colDetails.loc[colDetails['Country']=='Euro','Country']='Euro Area'\n",
    "colDetails.loc[colDetails['Country']=='Euro (inverse)','Country']='Euro Area (INVERSE)'\n",
    "colDetails.loc[colDetails['Country']=='Hong Kong','Country']='CHINA HONG KONG'\n",
    "colDetails.loc[colDetails['Country']=='Estonia','Country']='ESTONIAN'\n",
    "colDetails.loc[colDetails['Country']=='Jordan','Country']='JORDANIA'\n",
    "colDetails.loc[colDetails['Country']=='Serbia','Country']='SERBIA AND MONTENEGRO'\n",
    "colDetails.loc[colDetails['Country']=='Venezuela Soberano','Country']='VENEZUELA'\n",
    "colDetails.loc[colDetails['Country']=='Venezuela Fuerte','Country']='VENEZUELA'\n",
    "colDetails.loc[colDetails['Country']=='Cape Verde','Country']='CABO VERDE'\n",
    "colDetails.loc[colDetails['Country']=='Bosnia','Country']='BOSNIA AND HERZEGOWINA'\n",
    "colDetails.loc[colDetails['Country']=='Central Africa','Country']='CENTRAL AFRICAN REPUBLIC'\n",
    "colDetails.loc[colDetails['Country']=='Serbia','Country']='SERBIA AND MONTENEGRO'\n",
    "# colDetails.loc[colDetails['Country']=='Mauritania (Old)','Country']='MAURITANIA'\n",
    "colDetails.loc[colDetails['Country']=='Norwegian','Country']='NORWAY'\n",
    "colDetails.loc[colDetails['Country']=='Jordan','Country']='JORDANIA'\n",
    "colDetails.loc[colDetails['Country']=='Jordan','Country']='JORDANIA'\n",
    "colDetails.loc[colDetails['Country']=='Jordan','Country']='JORDANIA'\n",
    "\n",
    "\n",
    "\n",
    "# remove duplicate NZ, Australia  and Mexico columns\n",
    "FX_Spot_temp = FX_Spot_temp.drop(columns=['TDNZDSP','MXPSUF.','TDAUDSP'])\n",
    "\n",
    "\n",
    "# make all upper case\n",
    "colDetails.loc[:,'Country']=colDetails['Country'].str.upper()\n",
    "\n",
    "FX_Spot_temp =FX_Spot_temp.rename(columns = colDetails.set_index('Symbol')['Country'])\n",
    "FX_Spot_temp=FX_Spot_temp.rename(columns={'Code':'Date'})\n",
    "FX_Spot_temp['Date'] =pd.to_datetime(FX_Spot_temp['Date'])\n",
    "\n",
    "FX_Spot_temp = FX_Spot_temp.drop(columns=['SIERRA LEONE (OLD)','MAURITANIA (OLD)','CUBA','NGN PARALLEL','DELETE','NORTH KOREA','EAST CARIBBEAN','WEST AFRICA','VENEZUELA','FRENCH PACIFIC','CAYMAN ISLANDS'])\n",
    "\n",
    "for nam in FX_Spot_temp.columns:\n",
    "    if '(INVERSE)' in nam:\n",
    "        # remove inverse from name\n",
    "        newNam = nam.replace(' (INVERSE)','')\n",
    "        FX_Spot_temp=FX_Spot_temp.rename(columns={nam:newNam})\n",
    "        \n",
    "        # invert series\n",
    "        FX_Spot_temp.loc[:,newNam]=1.0/FX_Spot_temp.loc[:,newNam]\n",
    "\n",
    "\n",
    "    # now replace country with IMF code\n",
    "FX_Spot_temp = FX_Spot_temp.rename(columns = IMF_codes.set_index('Country')['IMF Code'].astype('str'))\n",
    "\n",
    "path_codeNames =path_rawdata\n",
    "# IMF codes for spot rate countries\n",
    "country_codes_spot = FX_Spot_temp.columns[1:]\n",
    "    \n",
    "FX_Spot = FX_Spot_temp.copy()\n",
    "FX_Fwd = FX_Fwd_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f292953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>IMF Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EURO AREA</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country  IMF Code\n",
       "28  EURO AREA       163"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMF_codes[IMF_codes['Country']=='EURO AREA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6110952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries out of excel file with IMF codes\n",
    "IMF_codes = pd.read_excel(path_codeNames+'IMF_codes.xlsx',header=None,names=['Country', 'IMF Code'])\n",
    "IMF_dict = IMF_codes.set_index('Country').to_dict()['IMF Code']\n",
    "IMF_dict_inv = IMF_codes.set_index('IMF Code').to_dict()['Country']\n",
    "\n",
    "# using spot code countries only:\n",
    "country_codes_num = [eval(i) for i in country_codes_spot]\n",
    "# Create list of countries in Barclays dataset (to be saved)\n",
    "List_names = [IMF_dict_inv[key] for key in country_codes_num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "003c077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove outliers (forward rates only for select countries, below)\n",
    "def remove_outliers(startdate, enddate, country):\n",
    "    col_country = IMF_dict[country]\n",
    "    FX_Fwd.loc[(FX_Fwd.Date>=pd.to_datetime(startdate,infer_datetime_format=True)) & (FX_Fwd.Date<=pd.to_datetime(enddate,infer_datetime_format=True)),[str(col_country)]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae7b666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# --------------------------- Corrections ------------------------------\n",
    "# ----------------------------------------------------------------------\n",
    "# For all the corrections below, need to change dates once use real data\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# deleting euro countries\n",
    "# after 12/31/1998, keep only euro data, write NaN for the euro countries\n",
    "# excluding greece, delete for spot rates only\n",
    "# after 01/31/2001, write NaN for Greece (174), delete for spot rates only\n",
    "eurocountries = ['BELGIUM', 'GERMANY', 'GREECE', 'SPAIN', 'FRANCE', 'IRELAND', \n",
    "                  'ITALY', 'LUXEMBOURG', 'NETHERLANDS', 'AUSTRIA', \n",
    "                  'PORTUGAL', 'FINLAND']\n",
    "# endsomeeuro_spot = '1/21/1997' # for testing only\n",
    "# endgreece_spot = '1/24/1997' # for testing only\n",
    "endsomeeuro_spot = '12/31/1998'\n",
    "endgreece_spot = '01/31/2001'\n",
    "for country in eurocountries:\n",
    "    col_country = IMF_dict[country]\n",
    "    if country != 'GREECE':\n",
    "        FX_Spot.loc[FX_Spot.Date>=pd.to_datetime(endsomeeuro_spot),str(col_country)] = np.nan\n",
    "    elif country == 'GREECE':\n",
    "        FX_Spot.loc[FX_Spot.Date>=pd.to_datetime(endgreece_spot),str(col_country)] = np.nan\n",
    "\n",
    "        \n",
    "# keep only countries for which we have both forward and spot exchange rates\n",
    "spotcolumns = list(FX_Spot.columns)\n",
    "fwdcolumns = list(FX_Fwd.columns)\n",
    "columnsinboth = list(set(spotcolumns) & set(fwdcolumns))\n",
    "columnsinboth.insert(0, columnsinboth.pop(columnsinboth.index('Date')))\n",
    "FX_Spot = FX_Spot[columnsinboth]\n",
    "FX_Fwd = FX_Fwd[columnsinboth]\n",
    "\n",
    "\n",
    "# remove outliers in forward rates\n",
    "\n",
    "# indonesia: remove from 29-Dec-2000 to 31-May-2007\n",
    "# remove_outliers('1/19/1997', '1/25/1997', 'INDONESIA') #for testing only\n",
    "remove_outliers('29/12/2000', '31/05/2007', 'INDONESIA')\n",
    "\n",
    "# south africa: remove from 31-Jul-1985 to 30-Aug-1985\n",
    "# remove_outliers('1/01/1997', '1/10/1997', 'SOUTH AFRICA') #for testing only\n",
    "remove_outliers('31/07/1985', '30/08/1985', 'SOUTH AFRICA')\n",
    "\n",
    "# turkey: remove from 31-Oct-2000 to 30-Nov-2001\n",
    "# remove_outliers('1/01/1997', '1/10/1997', 'TURKEY') #for testing only\n",
    "remove_outliers('31/10/2000', '30/11/2001', 'TURKEY')\n",
    "\n",
    "# malaysia: remove from 31-Aug-1998 to 30-Jun-2005\n",
    "# remove_outliers('1/05/1997', '1/15/1997', 'MALAYSIA') #for testing only\n",
    "remove_outliers('31/08/1998', '30/06/2005', 'MALAYSIA')\n",
    "\n",
    "# UAE: remove from 30-Jun-2006 to 30-Nov-2006\n",
    "# remove_outliers('1/20/1997', '1/30/1997', 'UNITED ARAB EMIRATES') #for testing only\n",
    "remove_outliers('30/06/2006', '30/11/2006', 'UNITED ARAB EMIRATES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92421b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the reuters data is not extended to end of month\n",
    "Reuters_FX_Fwd_D = FX_Fwd.copy()\n",
    "Reuters_FX_Spot_D = FX_Spot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b625a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save using pickle\n",
    "Reuters_FX_Fwd_D.to_pickle(path_cleandata+'Reuters_FX_Fwd_D'+'.pkl')\n",
    "Reuters_FX_Spot_D.to_pickle(path_cleandata+'Reuters_FX_Spot_D'+'.pkl')\n",
    "\n",
    "# with open(path_cleandata+'Reuters_Countries.pkl', 'wb') as f:\n",
    "#     pickle.dump(List_names, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc91411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import xlrd\n",
    "import pickle\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import calendar\n",
    "import country_converter as coco\n",
    "import os as os\n",
    "from dotenv import dotenv_values, find_dotenv\n",
    "\n",
    "# this looks for your configuration file and then reads it as a dictionary\n",
    "config = dotenv_values(find_dotenv())\n",
    "\n",
    "# set path using the dictionary key for which one you want\n",
    "path_cleandata = os.path.abspath(config[\"CLEANDATA\"]) + '\\\\'\n",
    "path_rawdata = os.path.abspath(config[\"RAWDATA\"]) + '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec8cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Reuters forward rates\n",
    "Reuters_FX_Fwd_D = pd.read_pickle(path_cleandata+'Reuters_FX_Fwd_D'+'.pkl')\n",
    "\n",
    "# Import Reuters spot rates\n",
    "Reuters_FX_Spot_D = pd.read_pickle(path_cleandata+'Reuters_FX_Spot_D'+'.pkl')\n",
    "\n",
    "# Import Barclays forward rates\n",
    "Barclays_FX_Fwd_D = pd.read_pickle(path_cleandata+'Barclays_FX_Fwd_D'+'.pkl')\n",
    "\n",
    "# Import Barclays spot rates\n",
    "Barclays_FX_Spot_D = pd.read_pickle(path_cleandata+'Barclays_FX_Spot_D'+'.pkl')\n",
    "\n",
    "# for some reason my data has these column names. Need to go back to Barclays \n",
    "Barclays_FX_Spot_D.rename(columns={\"index\": \"Date\"}, inplace=True)\n",
    "Barclays_FX_Fwd_D.rename(columns={\"index\": \"Date\"}, inplace=True)\n",
    "\n",
    "# use only 1988 and after for barclays data\n",
    "Barclays_FX_Spot_D = Barclays_FX_Spot_D.loc[Barclays_FX_Spot_D[\"Date\"] >= pd.to_datetime('1/01/1988')]\n",
    "Barclays_FX_Fwd_D = Barclays_FX_Fwd_D.loc[Barclays_FX_Fwd_D[\"Date\"] >= pd.to_datetime('1/01/1988')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db718fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trim series so that all end on the same day\n",
    "# barclays spot/forward series end on 31/01/2009 and reuters spot/forward series end on 01/01/2009\n",
    "# so the barclays series should be trimmed to end on 01/01/2009\n",
    "# don't have to redo for forward rates since they end at the same times\n",
    "end_barclays = max(list(Barclays_FX_Spot_D['Date']))\n",
    "end_reuters = max(list(Reuters_FX_Spot_D['Date']))\n",
    "common_end = min([end_barclays, end_reuters]) # should give us 01/01/2009\n",
    "\n",
    "all_data = [Barclays_FX_Spot_D, Reuters_FX_Spot_D, Barclays_FX_Fwd_D, Reuters_FX_Fwd_D]\n",
    "\n",
    "for data in all_data:\n",
    "    \n",
    "    data.drop(data[data[\"Date\"] >= common_end].index, inplace=True)\n",
    "    \n",
    "    data.set_index('Date', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd120509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find list of countries that show up in only Reuters, only Barclays, and both\n",
    "# the _s lists should be the same as the _f lists, just doing this to make sure\n",
    "countriesinboth_s = list(set(Reuters_FX_Spot_D.columns) & set(Barclays_FX_Spot_D.columns))\n",
    "onlyreuterscountries_s = [country for country in list(Reuters_FX_Spot_D.columns) if country not in countriesinboth_s]\n",
    "onlybarclayscountries_s =  [country for country in list(Barclays_FX_Spot_D.columns) if country not in countriesinboth_s]\n",
    "\n",
    "countriesinboth_f = list(set(Reuters_FX_Fwd_D.columns) & set(Barclays_FX_Fwd_D.columns))\n",
    "onlyreuterscountries_f = [country for country in list(Reuters_FX_Fwd_D.columns) if country not in countriesinboth_f]\n",
    "onlybarclayscountries_f =  [country for country in list(Barclays_FX_Fwd_D.columns) if country not in countriesinboth_f]\n",
    "\n",
    "# mergedate = pd.to_datetime('1/01/1997') # for testing only\n",
    "mergedate = pd.to_datetime('12/31/1996')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97187991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create merged data: spot rates\n",
    "\n",
    "# for countries only in Reuters or only in Barclays, will add the data as additional columns\n",
    "onlyB_Spot_data = Barclays_FX_Spot_D[onlybarclayscountries_s]\n",
    "onlyR_Spot_data = Reuters_FX_Spot_D[onlyreuterscountries_s]\n",
    "\n",
    "# for countries in both, take Barclays data until 01/01/1997\n",
    "BR_Spot_data_1 = Barclays_FX_Spot_D[countriesinboth_s].loc[Barclays_FX_Spot_D.index <= mergedate]\n",
    "# then take Reuters data afterwards\n",
    "BR_Spot_data_2 = Reuters_FX_Spot_D[countriesinboth_s].loc[Reuters_FX_Spot_D.index > mergedate]\n",
    "# merging everything\n",
    "BR_Spot_D = pd.concat([BR_Spot_data_1, BR_Spot_data_2]).join(onlyB_Spot_data).join(onlyR_Spot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943d5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create merged data: forward rates\n",
    "\n",
    "# for countries only in Reuters or only in Barclays, will add the data as additional columns\n",
    "onlyB_Fwd_data = Barclays_FX_Fwd_D[onlybarclayscountries_f]\n",
    "onlyR_Fwd_data = Reuters_FX_Fwd_D[onlyreuterscountries_f]\n",
    "\n",
    "# for countries in both, take Barclays data until 01/01/1997\n",
    "BR_Fwd_data_1 = Barclays_FX_Fwd_D[countriesinboth_f].loc[Barclays_FX_Fwd_D.index <= mergedate]\n",
    "# then take Reuters data afterwards\n",
    "BR_Fwd_data_2 = Reuters_FX_Fwd_D[countriesinboth_f].loc[Reuters_FX_Fwd_D.index > mergedate]\n",
    "# merging everything\n",
    "BR_Fwd_D = pd.concat([BR_Fwd_data_1, BR_Fwd_data_2]).join(onlyB_Fwd_data).join(onlyR_Fwd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d363c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries out of excel file with IMF codes\n",
    "IMF_codes = pd.read_excel(path_rawdata+'IMF_codes.xls',header=None,names=['Country', 'IMF Code'])\n",
    "IMF_dict = IMF_codes.set_index('Country').to_dict()['IMF Code']\n",
    "IMF_dict_inv = IMF_codes.set_index('IMF Code').to_dict()['Country']\n",
    "\n",
    "# get list of countries\n",
    "country_codes_spot = list(BR_Spot_D.columns)\n",
    "\n",
    "# using spot code countries only\n",
    "# don't have to redo for forward rates since they have the same sets of countries\n",
    "country_codes_num = [eval(i) for i in country_codes_spot]\n",
    "# Create list of countries in merged dataset (to be saved)\n",
    "List_names = [IMF_dict_inv[key] for key in country_codes_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea6d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend sample to End-of-Month\n",
    "\n",
    "def Extend_EndofMonth(data):\n",
    "    \n",
    "    # find date of last entry\n",
    "    last_entry = data.index[-1]\n",
    "    last_year = last_entry.year\n",
    "    last_month = last_entry.month\n",
    "    \n",
    "    # date to extend to (the end of the month of last entry)\n",
    "    to_extend = datetime.datetime(year=last_year, month=last_month, day=calendar.monthrange(last_year, last_month)[1])\n",
    "    \n",
    "    # create dates to end of month\n",
    "    dates_to_add = pd.date_range(data.index[-1],to_extend,freq='d')\n",
    "    \n",
    "    # create a dataframe with dates_to_add as index and filled in values, then append this to the end of original data\n",
    "    idx = data.index.union(dates_to_add)\n",
    "    \n",
    "    # print(dates_to_add)\n",
    "    \n",
    "    # fill out values\n",
    "    extended = data.reindex(idx, method='ffill')\n",
    "    return extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ade92f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BR_Spot_D = Extend_EndofMonth(BR_Spot_D)\n",
    "BR_Fwd_D = Extend_EndofMonth(BR_Fwd_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00efa028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert index to datetimeindex (necessary for monthly conversion)\n",
    "\n",
    "BR_Spot_D.index = pd.to_datetime(BR_Spot_D.index, format='%Y-%m-%d')\n",
    "BR_Fwd_D.index = pd.to_datetime(BR_Fwd_D.index, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "431bc353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert to monthly (end-of-month)\n",
    "BR_Spot_M = BR_Spot_D.groupby(BR_Spot_D.index.strftime('%Y-%m')).last()\n",
    "BR_Fwd_M = BR_Fwd_D.groupby(BR_Fwd_D.index.strftime('%Y-%m')).last()\n",
    "\n",
    "# when the dates were converted to monthly, the index became a string, so need to convert all back to datetime\n",
    "BR_Spot_M.index = pd.to_datetime(BR_Spot_M.index)\n",
    "BR_Fwd_M.index = pd.to_datetime(BR_Fwd_M.index)\n",
    "BR_Spot_M.index = BR_Spot_M.index + pd.offsets.MonthEnd(0)\n",
    "BR_Fwd_M.index = BR_Fwd_M.index + pd.offsets.MonthEnd(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe0e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save monthly data using pickle\n",
    "\n",
    "BR_Spot_M.to_pickle(path_cleandata+'BR_Spot_dM'+'.pkl')\n",
    "BR_Fwd_M.to_pickle(path_cleandata+'BR_Fwd_dM'+'.pkl')\n",
    "\n",
    "with open(path_cleandata+'BR_Countries.pkl', 'wb') as f:\n",
    "    pickle.dump(List_names, f)\n",
    "    \n",
    "# Save daily data using pickle\n",
    "BR_Spot_D.to_pickle(path_cleandata+'BR_Spot_D'+'.pkl')\n",
    "BR_Fwd_D.to_pickle(path_cleandata+'BR_Fwd_D'+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e884a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

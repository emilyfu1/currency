{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b28ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import xlrd\n",
    "import pickle\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import calendar\n",
    "import country_converter as coco\n",
    "import os\n",
    "\n",
    "\n",
    "# Options for loading and saving\n",
    "LoadDataType = 'Ours' # options: 'Ours','Test','Stanford'\n",
    "#saveAppend = '_OurData_NScode'\n",
    "saveAppend = ''\n",
    "\n",
    "\n",
    "                 \n",
    "if LoadDataType=='Test':\n",
    "    \n",
    "    # IMF codes of countries in Barclays dataset\n",
    "    country_codes = ['112', '136', '124', '132', '146', '134', '138','158','532','199',\\\n",
    "                 '156', '576', '548', '193', '196', '144','142', '128', '163']\n",
    "    \n",
    "    # Set current directory as path_rawdata\n",
    "    path_rawdata = os.path.normpath(os.getcwd()+os.sep+os.pardir)+'/RawData/'\n",
    "    \n",
    "    # Import Barclays forward rates\n",
    "    # FX_Fwd_temp = pd.read_excel(path_rawdata+'Barclays_D.xlsx', sheet_name='Fwd1', skiprows=1)\n",
    "    \n",
    "    # Import Barclays forward rates (using my tester dataset)\n",
    "    FX_Fwd_temp = pd.read_excel(path_rawdata+'Barclays_D_fortesting.xlsx', sheet_name='Fwd1', skiprows=1)\n",
    "    \n",
    "    # Convert date to datetime object (from excel format which counts days since 1900)\n",
    "    date_column = pd.to_datetime(FX_Fwd_temp['Code'], unit='D', origin='1899-12-31')\n",
    "    FX_Fwd_temp.insert(0, 'Date', date_column)\n",
    "    FX_Fwd_temp = FX_Fwd_temp.drop(['Code'],axis=1)\n",
    "    \n",
    "    \n",
    "    # Change column names to Date (for first column) and IMF country codes (for all other columns)\n",
    "\n",
    "    column_names = ['Date'] + country_codes\n",
    "\n",
    "    FX_Fwd_temp.columns = column_names\n",
    "    \n",
    "    # Import Barclays spot rates\n",
    "    # FX_Spot_temp = pd.read_excel(path_rawdata+'Barclays_D.xlsx', sheet_name='spot', skiprows=1)\n",
    "\n",
    "    # Import Barclays spot rates (using my tester dataset)\n",
    "    FX_Spot_temp = pd.read_excel(path_rawdata+'Barclays_D_fortesting.xlsx', sheet_name='spot', skiprows=1)\n",
    "\n",
    "    # Convert date to datetime object (from excel format which counts days since 1900)\n",
    "    date_column = pd.to_datetime(FX_Spot_temp['Code'], unit='D', origin='1899-12-31')\n",
    "    FX_Spot_temp.insert(0, 'Date', date_column)\n",
    "    FX_Spot_temp = FX_Spot_temp.drop(['Code'],axis=1)\n",
    "\n",
    "    # Change column names to Date (for first column) and IMF country codes (for all other columns)\n",
    "    FX_Spot_temp.columns = column_names\n",
    "    \n",
    "    path_codeNames = path_rawdata\n",
    "elif LoadDataType=='Ours':\n",
    "    # Set current directory as path_rawdata\n",
    "    path_rawdata = os.path.normpath(os.getcwd()+os.sep+os.pardir)+\"/RawData/\"\n",
    "    \n",
    "    # Import Barclays forward rates (using actual dataset)\n",
    "    FX_Fwd_temp = pd.read_excel(path_rawdata+'Datastream & Barclays - Spots & 1M Forwards.xlsx', sheet_name='Barclays FX Fwd', skiprows=0)\n",
    "\n",
    "    # Convert column names to country names (Nick comment: I don't like the hard coded method of the fake data)\n",
    "    colDetails =  pd.read_excel(path_rawdata+'Exchange Rates - Barclays.xlsx', sheet_name='Barclays FX Fwd Codes', skiprows=0)\n",
    "    colDetails = colDetails[['Symbol','Country','From Currency','To Currency']]\n",
    "    colDetails = colDetails[colDetails['Symbol'].isin(FX_Fwd_temp.columns)]\n",
    "    \n",
    "    # fix couple of outlier labels\n",
    "    colDetails.loc[colDetails['Country']=='Euro','Country']='Euro Area'\n",
    "    colDetails.loc[colDetails['Country']=='Hong Kong','Country']='CHINA HONG KONG'\n",
    "    \n",
    "    # make upper case\n",
    "    colDetails.loc[:,'Country']=colDetails['Country'].str.upper()\n",
    "    \n",
    "    # drop duplicate Euro series (keep one that only exists post Euro creation - so no synthetic Euro)\n",
    "    FX_Fwd_temp = FX_Fwd_temp.drop(columns=['BBDM.1F','BBXEU1F'])\n",
    "    FX_Fwd_temp =FX_Fwd_temp.rename(columns = colDetails.set_index('Symbol')['Country'])\n",
    "\n",
    "    for nam in FX_Fwd_temp.columns:\n",
    "        if '(INVERSE)' in nam:\n",
    "            # remove inverse from name\n",
    "            newNam = nam.replace(' (INVERSE)','')\n",
    "            FX_Fwd_temp=FX_Fwd_temp.rename(columns={nam:newNam})\n",
    "            \n",
    "            # invert series\n",
    "            FX_Fwd_temp.loc[:,newNam]=1.0/FX_Fwd_temp.loc[:,newNam]\n",
    "            \n",
    "            \n",
    "    # now replace country with IMF code\n",
    "    IMF_codes = pd.read_excel(path_rawdata+'IMF_codes.xls',header=None,names=['Country', 'IMF Code'])\n",
    "    FX_Fwd_temp = FX_Fwd_temp.rename(columns = IMF_codes.set_index('Country')['IMF Code'].astype('str'))\n",
    "    \n",
    "    country_codes = FX_Fwd_temp.columns[1:]\n",
    "    \n",
    "    # Now repeat the same with the spot data!\n",
    "    FX_Spot_temp = pd.read_excel(path_rawdata+'Datastream & Barclays - Spots & 1M Forwards.xlsx', sheet_name='Barclays Spot', skiprows=0)\n",
    "\n",
    "    # Convert column names to country names (Nick comment: I don't like the hard coded method of the fake data)\n",
    "    colDetails =  pd.read_excel(path_rawdata+'Exchange Rates - Barclays.xlsx', sheet_name='Barclays Spot Codes', skiprows=0)\n",
    "    colDetails = colDetails[['Symbol','Country']]\n",
    "    colDetails = colDetails[colDetails['Symbol'].isin(FX_Spot_temp.columns)]\n",
    "    \n",
    "    # fix couple of outlier labels\n",
    "    colDetails.loc[colDetails['Country']=='Euro','Country']='Euro Area'\n",
    "    colDetails.loc[colDetails['Country']=='Hong Kong','Country']='CHINA HONG KONG'\n",
    "    \n",
    "    # make upper case\n",
    "    colDetails.loc[:,'Country']=colDetails['Country'].str.upper()\n",
    "    \n",
    "    FX_Spot_temp =FX_Spot_temp.rename(columns = colDetails.set_index('Symbol')['Country'])\n",
    "    FX_Spot_temp=FX_Spot_temp.rename(columns={'Code':'Date'})\n",
    "    \n",
    "    for nam in FX_Spot_temp.columns:\n",
    "        if '(INVERSE)' in nam:\n",
    "            # remove inverse from name\n",
    "            newNam = nam.replace(' (INVERSE)','')\n",
    "            FX_Spot_temp=FX_Spot_temp.rename(columns={nam:newNam})\n",
    "            \n",
    "            # invert series\n",
    "            FX_Spot_temp.loc[:,newNam]=1.0/FX_Spot_temp.loc[:,newNam]\n",
    "    \n",
    "\n",
    "     # now replace country with IMF code\n",
    "    FX_Spot_temp = FX_Spot_temp.rename(columns = IMF_codes.set_index('Country')['IMF Code'].astype('str'))\n",
    "    \n",
    "    path_codeNames = path_rawdata\n",
    "    country_codes = FX_Spot_temp.columns[1:]\n",
    "elif LoadDataType=='Stanford':\n",
    "    path_rawdata = os.path.normpath(os.getcwd()+os.sep+os.pardir)+'/RawData/Stanford Data/ToUpdate/'\n",
    "    path_codeNames = os.path.normpath(os.getcwd()+os.sep+os.pardir+os.sep+os.pardir)+\"/Nick and Jamie's Barclays and Reuters/Raw and processed data/toUse/\"\n",
    "    \n",
    "    \n",
    "    # Import Barclays forward rates (using actual dataset)\n",
    "    FX_Fwd_temp = pd.read_excel(path_rawdata+'DataRequests_Barclays_FW1F_D.xlsm', sheet_name='Sheet1', skiprows=1)\n",
    "    \n",
    "    # Convert date to datetime object (from excel format which counts days since 1900)\n",
    "    date_column = pd.to_datetime(FX_Fwd_temp['Code'], unit='D', origin='1899-12-31')\n",
    "    FX_Fwd_temp.insert(0, 'Date', date_column)\n",
    "    FX_Fwd_temp = FX_Fwd_temp.drop(['Code'],axis=1)\n",
    "    \n",
    "    # remove (ER) from column names\n",
    "    nams = FX_Fwd_temp.columns\n",
    "    for nam in nams:\n",
    "        newNam = nam.replace('(ER)','')\n",
    "        \n",
    "        FX_Fwd_temp=FX_Fwd_temp.rename(columns={nam:newNam})\n",
    "        if 'Unnamed' in nam:\n",
    "            FX_Fwd_temp=FX_Fwd_temp.drop(columns=nam)\n",
    "          \n",
    "    # import column names sheet\n",
    "     # Convert column names to country names (Nick comment: I don't like the hard coded method of the fake data)\n",
    "    colDetails =  pd.read_excel(path_codeNames+'Exchange Rates - Barclays.xlsx', sheet_name='Barclays FX Fwd Codes', skiprows=0)\n",
    "    colDetails = colDetails[['Symbol','Country','From Currency','To Currency']]\n",
    "    colDetails = colDetails[colDetails['Symbol'].isin(FX_Fwd_temp.columns)]\n",
    "\n",
    "    # fix couple of outlier labels\n",
    "    colDetails.loc[colDetails['Country']=='Euro','Country']='Euro Area'\n",
    "    colDetails.loc[colDetails['Country']=='Hong Kong','Country']='CHINA HONG KONG'\n",
    "    \n",
    "    # make upper case\n",
    "    colDetails.loc[:,'Country']=colDetails['Country'].str.upper()\n",
    "   \n",
    "    # Add in custom new rows (to DELETE ASAP)\n",
    "    #colDetails_toAppend = {'Country':'BELGIUM','Symbol':'BBBEL1F'}\n",
    "    #colDetails=pd.concat([colDetails,pd.DataFrame(colDetails_toAppend,index=[0])],ignore_index=True)\n",
    "    #colDetails_toAppend = {'Country':'NETHERLANDS','Symbol':'BBNLG1F'}\n",
    "    #colDetails=pd.concat([colDetails,pd.DataFrame(colDetails_toAppend,index=[0])],ignore_index=True)\n",
    "    #colDetails_toAppend = {'Country':'MALAYSIA','Symbol':'BBMYR1F'}\n",
    "    #colDetails=pd.concat([colDetails,pd.DataFrame(colDetails_toAppend,index=[0])],ignore_index=True)\n",
    "    \n",
    "    # drop duplicate Euro series (keep one that only exists post Euro creation - so no synthetic Euro)\n",
    "    #FX_Fwd_temp = FX_Fwd_temp.drop(columns=['BBDM.1F','BBXEU1F'])\n",
    "    \n",
    "    FX_Fwd_temp =FX_Fwd_temp.rename(columns = colDetails.set_index('Symbol')['Country'])\n",
    "\n",
    "    for nam in FX_Fwd_temp.columns:\n",
    "        if '(INVERSE)' in nam:\n",
    "            # remove inverse from name\n",
    "            newNam = nam.replace(' (INVERSE)','')\n",
    "            FX_Fwd_temp=FX_Fwd_temp.rename(columns={nam:newNam})\n",
    "            \n",
    "            # invert series\n",
    "            FX_Fwd_temp.loc[:,newNam]=1.0/FX_Fwd_temp.loc[:,newNam]\n",
    "            \n",
    "            \n",
    "    # now replace country with IMF code\n",
    "    IMF_codes = pd.read_excel(path_codeNames+'IMF_codes.xls',header=None,names=['Country', 'IMF Code'])\n",
    "    FX_Fwd_temp = FX_Fwd_temp.rename(columns = IMF_codes.set_index('Country')['IMF Code'].astype('str'))\n",
    "   \n",
    "    country_codes = FX_Fwd_temp.columns[1:]\n",
    "    \n",
    "    # Now repeat the same with the spot data!\n",
    "    FX_Spot_temp = pd.read_excel(path_rawdata+'DataRequests_Barclays_SP_D.xlsm', sheet_name='Sheet1', skiprows=1)\n",
    "    \n",
    "    # Convert date to datetime object (from excel format which counts days since 1900)\n",
    "    date_column = pd.to_datetime(FX_Spot_temp['Code'], unit='D', origin='1899-12-31')\n",
    "    FX_Spot_temp.insert(0, 'Date', date_column)\n",
    "    FX_Spot_temp = FX_Spot_temp.drop(['Code'],axis=1)\n",
    "    \n",
    "    # remove (ER) from column names\n",
    "    nams = FX_Spot_temp.columns\n",
    "    for nam in nams:\n",
    "        newNam = nam.replace('(ER)','')\n",
    "        \n",
    "        FX_Spot_temp=FX_Spot_temp.rename(columns={nam:newNam})\n",
    "        if 'Unnamed' in nam:\n",
    "            FX_Spot_temp=FX_Spot_temp.drop(columns=nam)\n",
    "    \n",
    "    \n",
    "    # Convert column names to country names (Nick comment: I don't like the hard coded method of the fake data)\n",
    "    colDetails =  pd.read_excel(path_codeNames+'Exchange Rates - Barclays.xlsx', sheet_name='Barclays Spot Codes', skiprows=0)\n",
    "    colDetails = colDetails[['Symbol','Country']]\n",
    "    colDetails = colDetails[colDetails['Symbol'].isin(FX_Spot_temp.columns)]\n",
    "    \n",
    "    # fix couple of outlier labels\n",
    "    colDetails.loc[colDetails['Country']=='Euro','Country']='Euro Area'\n",
    "    colDetails.loc[colDetails['Country']=='Hong Kong','Country']='CHINA HONG KONG'\n",
    "    \n",
    "    # make upper case\n",
    "    colDetails.loc[:,'Country']=colDetails['Country'].str.upper()\n",
    "    \n",
    "    FX_Spot_temp =FX_Spot_temp.rename(columns = colDetails.set_index('Symbol')['Country'])\n",
    "    FX_Spot_temp=FX_Spot_temp.rename(columns={'Code':'Date'})\n",
    "    \n",
    "    for nam in FX_Spot_temp.columns:\n",
    "        if '(INVERSE)' in nam:\n",
    "            # remove inverse from name\n",
    "            newNam = nam.replace(' (INVERSE)','')\n",
    "            FX_Spot_temp=FX_Spot_temp.rename(columns={nam:newNam})\n",
    "            \n",
    "            # invert series\n",
    "            FX_Spot_temp.loc[:,newNam]=1.0/FX_Spot_temp.loc[:,newNam]\n",
    "    \n",
    "\n",
    "     # now replace country with IMF code\n",
    "    FX_Spot_temp = FX_Spot_temp.rename(columns = IMF_codes.set_index('Country')['IMF Code'].astype('str'))\n",
    "\n",
    "    path_rawdata = path_codeNames\n",
    "    country_codes = FX_Spot_temp.columns[1:]\n",
    "else:\n",
    "    print('ERROR!!!! You havent entered the right value for LoadDataType!')\n",
    "    error()\n",
    "\n",
    "# Use 1M Fwd only, as they are the only ones in Richmond's excel file (probably used 2M and 3M in earlier versions)\n",
    "FX_Fwd = FX_Fwd_temp.copy()\n",
    "FX_Spot = FX_Spot_temp.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72bc65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries out of excel file with IMF codes\n",
    "IMF_codes = pd.read_excel(path_codeNames+'IMF_codes.xls',header=None,names=['Country', 'IMF Code'])\n",
    "IMF_dict = IMF_codes.set_index('Country').to_dict()['IMF Code']\n",
    "IMF_dict_inv = IMF_codes.set_index('IMF Code').to_dict()['Country']\n",
    "country_codes_num = [eval(i) for i in country_codes]\n",
    "# Create list of countries in Barclays dataset (to be saved)\n",
    "List_names = [IMF_dict_inv[key] for key in country_codes_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eadc352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust exchange rate units (FX Forward and spot data are in units\n",
    "# of foreign currency per USD except for UK). So need to adjust UK \n",
    "# so all forward and spot data are in foreign currency per USD\n",
    "if LoadDataType=='Test':\n",
    "    col_UK = IMF_dict['UNITED KINGDOM']\n",
    "    FX_Spot[str(col_UK)] = 1.0/FX_Spot[str(col_UK)]\n",
    "    FX_Fwd[str(col_UK)] = 1.0/FX_Fwd[str(col_UK)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8da41431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# --------------------------- Corrections ------------------------------\n",
    "# ----------------------------------------------------------------------\n",
    "# For all the corrections below, need to change dates once use real data\n",
    "# ----------------------------------------------------------------------\n",
    "# Belgium - Series are stale starting in 12/19/1989 for future contracts \n",
    "# and 1/1/1990 for spot rates\n",
    "col_BE = IMF_dict['BELGIUM']\n",
    "# endBG_Spot = '1/5/1983'\n",
    "# endBG_Fwd = '1/8/1983'\n",
    "endBG_Spot = '1/1/1990'\n",
    "endBG_Fwd = '12/19/1989'\n",
    "FX_Spot.loc[FX_Spot.Date>=pd.to_datetime(endBG_Spot),str(col_BE)] = np.nan\n",
    "FX_Fwd.loc[FX_Fwd.Date>=pd.to_datetime(endBG_Fwd),str(col_BE)] = np.nan\n",
    "\n",
    "# Australia - Missing data for Fwd 1M on 10/1/2001 (and Fwd 3M on 12/1/1996)\n",
    "col_AU = IMF_dict['AUSTRALIA']\n",
    "# outlier_AU = '1/11/1983'\n",
    "outlier_AU = '10/1/2001'\n",
    "FX_Fwd.loc[FX_Fwd.Date==pd.to_datetime(outlier_AU),str(col_AU)] = np.nan\n",
    "\n",
    "# Norway - Replace min Fwd by NaN, need to figure out why\n",
    "col_NW = IMF_dict['NORWAY']\n",
    "row_NW = FX_Fwd[str(col_NW)].idxmin()\n",
    "FX_Fwd.at[row_NW,str(col_NW)] = np.nan\n",
    "\n",
    "# New Zealand - Replace max Fwd by NaN, need to figure out why\n",
    "col_NZ = IMF_dict['NEW ZEALAND']\n",
    "row_NZ = FX_Fwd[str(col_NZ)].idxmax()\n",
    "FX_Fwd.at[row_NZ,str(col_NZ)] = np.nan\n",
    "\n",
    "# Hong Kong - Replace max Fwd by NaN, need to figure out why\n",
    "col_HK = IMF_dict['CHINA HONG KONG']\n",
    "row_HK = FX_Fwd[str(col_HK)].idxmax()\n",
    "FX_Fwd.at[row_HK,str(col_HK)] = np.nan\n",
    "\n",
    "# Euro area countries - Delete spot and forward values for\n",
    "# Germany, France, Italy, Belgium and Netherlands from 1/1/1999 on\n",
    "# starteuro = '1/18/1983'\n",
    "starteuro = '1/1/1999'\n",
    "col_DE = IMF_dict['GERMANY']\n",
    "col_FR = IMF_dict['FRANCE']\n",
    "col_IT = IMF_dict['ITALY']\n",
    "col_BE = IMF_dict['BELGIUM']\n",
    "col_NL = IMF_dict['NETHERLANDS']\n",
    "col_euro = [str(col_DE),str(col_FR),str(col_IT),str(col_BE),str(col_NL)]\n",
    "\n",
    "FX_Spot.loc[FX_Spot.Date>=pd.to_datetime(starteuro),col_euro] = np.nan\n",
    "FX_Fwd.loc[FX_Fwd.Date>=pd.to_datetime(starteuro),col_euro] = np.nan\n",
    "\n",
    "Barclays_FX_Spot_D = FX_Spot.copy()\n",
    "Barclays_FX_Fwd_D = FX_Fwd.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a339669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend sample to End-of-Month\n",
    "\n",
    "def Extend_EndofMonth(data):\n",
    "    \n",
    "    data.set_index('Date', inplace=True)\n",
    "    \n",
    "    # find date of last entry\n",
    "    last_entry = data.index[-1]\n",
    "    last_year = last_entry.year\n",
    "    last_month = last_entry.month\n",
    "    \n",
    "    # date to extend to (the end of the month of last entry)\n",
    "    to_extend = datetime.datetime(year=last_year, month=last_month, day=calendar.monthrange(last_year, last_month)[1])\n",
    "    \n",
    "    # create dates to end of month\n",
    "    dates_to_add = pd.date_range(data.index[-1],to_extend,freq='d')\n",
    "    \n",
    "    # create a dataframe with dates_to_add as index and filled in values, then append this to the end of original data\n",
    "    idx = data.index.union(dates_to_add)\n",
    "    \n",
    "    # print(dates_to_add)\n",
    "    \n",
    "    # fill out values\n",
    "    extended = data.reindex(idx, method='ffill')\n",
    "    extended.reset_index(inplace=True)\n",
    "    return extended\n",
    "\n",
    "Barclays_FX_Spot_D_ex = Extend_EndofMonth(Barclays_FX_Spot_D)\n",
    "Barclays_FX_Fwd_D_ex = Extend_EndofMonth(Barclays_FX_Fwd_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df385459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save using pickle\n",
    "# Set current directory as newpath\n",
    "path_cleandata = os.path.normpath(os.getcwd()+os.sep+os.pardir)+'/CleanData/'\n",
    "# Barclays_FX_Fwd_D_ex.to_pickle(path_cleandata+'Barclays_FX_Fwd_D.pkl')\n",
    "# Barclays_FX_Spot_D_ex.to_pickle(path_cleandata+'Barclays_FX_Spot_D.pkl')\n",
    "\n",
    "# saving my cleaned tester data\n",
    "Barclays_FX_Fwd_D_ex.to_pickle(path_cleandata+'Barclays_FX_Fwd_D'+saveAppend+'.pkl')\n",
    "Barclays_FX_Spot_D_ex.to_pickle(path_cleandata+'Barclays_FX_Spot_D'+saveAppend+'.pkl')\n",
    "\n",
    "# with open(path_cleandata+'Barclays_Countries.pkl', 'wb') as f:\n",
    "#     pickle.dump(List_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaeebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

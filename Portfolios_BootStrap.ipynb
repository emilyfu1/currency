{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2c4f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import country_converter as coco\n",
    "import xlrd\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import dotenv_values, find_dotenv\n",
    "\n",
    "# this looks for your configuration file and then reads it as a dictionary\n",
    "config = dotenv_values(find_dotenv())\n",
    "\n",
    "cc = coco.CountryConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a68ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path using the dictionary key for which one you want\n",
    "path_cleandata = os.path.abspath(config[\"CLEANDATA\"]) + '\\\\'\n",
    "path_rawdata = os.path.abspath(config[\"RAWDATA\"]) + '\\\\'\n",
    "\n",
    "# loadAppend = '_OurData_NScode'\n",
    "# saveAppend = '_OurData_NScode'\n",
    "loadAppend = ''\n",
    "saveAppend = ''\n",
    "\n",
    "PortfolioData_load = path_cleandata+ 'PortfolioData' + loadAppend + '.pkl'\n",
    "Factors_FX_Portfolios_Cent = path_cleandata+'Factors_FX_Portfolios_Cent'+saveAppend+'.pkl'\n",
    "Factors_FX_Portfolios_Invoice = path_cleandata+'Factors_FX_Portfolios_Invoice'+saveAppend+'.pkl'\n",
    "PortfolioData_PortfolioRX_AllSorts_Cent = path_cleandata+'PortfolioData_PortfolioRX_AllSorts_Cent'+saveAppend+'.pkl'\n",
    "PortfolioData_PortfolioRX_AllSorts_Invoice = path_cleandata+'PortfolioData_PortfolioRX_AllSorts_Invoice'+saveAppend+'.pkl'\n",
    "PortfolioData_AllSorts_BootStrap = path_cleandata+'PortfolioData_AllSorts_BootStrap'+saveAppend+'.pkl'\n",
    "PortfolioData_BootStrap_centSort = path_cleandata+'PortfolioData_BootStrap_centSort'+saveAppend+'.pkl'\n",
    "PortfolioData_BootStrap_InvoiceSort = path_cleandata+'PortfolioData_BootStrap_InvoiceSort'+saveAppend+'.pkl'\n",
    "PortfolioData_BootStrap_FSSort = path_cleandata+'PortfolioData_BootStrap_FSSort'+saveAppend+'.pkl'\n",
    "PortfolioData_BootStrap_UnconditionalSort = path_cleandata+'PortfolioData_BootStrap_UnconditionalSort'+saveAppend+'.pkl'\n",
    "\n",
    "FullData_load = path_cleandata + 'FullData_TSICIO.pkl'\n",
    "\n",
    "name_to_ISO = pd.read_csv(path_rawdata+'Country_iso_codes.csv',usecols=['Name','iso3'],index_col='Name')\n",
    "\n",
    "developedcountries = ['Australia','Belgium','Canada','Denmark','France',\n",
    "                     'Germany','Italy','Japan','Netherlands','New Zealand',\n",
    "                     'Norway','Sweden','Switzerland','United Kingdom']\n",
    "\n",
    "# Create list of developed countries ISO codes\n",
    "listdeveloped = name_to_ISO.loc[developedcountries].squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79328d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "portsub = pd.read_pickle(PortfolioData_load)\n",
    "\n",
    "# Richmond replication\n",
    "portsub = portsub[portsub['year'].isin(list(range(1988,2016+1)))]\n",
    "portsub['cent'] = portsub['cent_exp']\n",
    "\n",
    "# Our work on invoicing currencies\n",
    "portsubours = pd.read_pickle(FullData_load)\n",
    "portsubours = portsubours[portsubours['year'].isin(list(range(1988,2016+1)))]\n",
    "portsubours['cent'] = portsubours['cent_exp']\n",
    "\n",
    "# Create sub-dataframe with only developed country data\n",
    "portsubdeveloped = portsub.loc[portsub['iso3'].isin(listdeveloped)]\n",
    "#portsubdeveloped = portsub[portsub['iso3'].isin(listdeveloped)].copy()\n",
    "portsuboursdeveloped = portsubours.loc[portsubours['iso3'].isin(listdeveloped)]\n",
    "\n",
    "numports = 4\n",
    "\n",
    "sampsize = len(portsub)\n",
    "\n",
    "# Function taking dataseries as input, sorting them into bins, and returning the bin categories\n",
    "def GetPortNums(ds,numports):\n",
    "    #return pd.qcut(ds,q=numports,labels=False,duplicates='drop')\n",
    "    return pd.qcut(ds,q=numports,labels=False)\n",
    "\n",
    "# Function to annualize monthly mean\n",
    "def mean1200(series):\n",
    "    return np.mean(series)*1200\n",
    "\n",
    "# Function to annualize monthly std\n",
    "def std12(series):\n",
    "    return np.std(series)*math.sqrt(12)*100\n",
    "\n",
    "# Function to compute Sharpe ratio\n",
    "def SR12(series):\n",
    "    return np.mean(series)*1200/(np.std(series)*math.sqrt(12)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c6aad839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# --------| Sort on centrality |----------\n",
    "# ----------------------------------------\n",
    "\n",
    "# Define function computing means by portfolios\n",
    "def getCentMeans(portsubin):\n",
    "    portsubin.sort_values(by=['iso3', 'Date'], inplace=True)\n",
    "    portsubin['prevcent'] = portsubin.groupby('iso3')['cent'].shift(12)\n",
    "    portsubin['prevfwdspread'] = portsubin.groupby('iso3')['forwardspread'].shift(1)\n",
    "    \n",
    "    # We want to have risk premia info and the centrality variable to rank on\n",
    "    portsubin.dropna(subset=['logrx','prevcent'], inplace=True)\n",
    "    \n",
    "    # sort on last year's centrality (add one since categories start at 0 otherwise)\n",
    "    portsubin['portnum'] = (1 + portsubin.groupby('year',group_keys=False)['prevcent']\n",
    "                            .apply(GetPortNums,numports=numports)\n",
    "                           )\n",
    "\n",
    "    # get averages within portfolio at each given date\n",
    "    portbydate = ( portsubin.groupby(by=['Date','portnum'],as_index=False)\n",
    "                  .agg({'logrx':'mean', \n",
    "                        'forwardspread':'mean', \n",
    "                        'realfwdspread':'mean',\n",
    "                        'prevcent':['count','mean'], \n",
    "                        'consrs_pwt':'mean'})\n",
    "                 )\n",
    "    portbydate.columns = ['Date','portnum', \n",
    "                         'logrx', 'forwardspread','realfwdspread',\n",
    "                          'numcountries','prevcent','conscor']\n",
    "    \n",
    "    # get a high minus low portfolio\n",
    "    # reshape to long form with new 'measure' column\n",
    "    longform = pd.melt(portbydate,id_vars=['Date','portnum'],var_name='measure')\n",
    "    # reshape to wide form but this time with the portfolios in columns\n",
    "    byportfolio = longform.pivot_table(index=['Date','measure'],columns='portnum',values='value').reset_index()\\\n",
    "            .rename_axis(None, axis=1)\n",
    "    # compute returns with various measures of HML portfolio\n",
    "    byportfolio['HML'] = byportfolio[1] - byportfolio[4]\n",
    "    # reshape to long form again, with 'measure' column\n",
    "    tmp = pd.melt(byportfolio, id_vars=['Date','measure'],var_name='portnum')\n",
    "    # reshape to wide form again, with HML being another colum in addition to the numbered portfolios\n",
    "    portbydate = tmp.pivot_table(index=['Date','portnum'],columns='measure',values='value').reset_index()\\\n",
    "            .rename_axis(None, axis=1)\n",
    "    \n",
    "    # get averages within portfolio at each given date\n",
    "    portmeans = ( portbydate.groupby(by=['portnum'],as_index=False)\n",
    "               .agg({'prevcent':'mean',\n",
    "                     'numcountries':'mean',\n",
    "                     'logrx':[mean1200,std12],\n",
    "                     'forwardspread':mean1200,\n",
    "                     'realfwdspread':mean1200,\n",
    "                     'conscor':'mean'\n",
    "                    })\n",
    "             )\n",
    "    portmeans.columns = ['portnum', 'prevcent', 'numcountries', \n",
    "                         'logrx', 'sdlogrx', 'forwardspread',\n",
    "                         'realfwdspread','conscor']\n",
    "    portmeans['sharperatio'] = portmeans['logrx']/portmeans['sdlogrx']\n",
    "    \n",
    "    return portmeans, portbydate\n",
    "    \n",
    "portsubin = portsub.copy()\n",
    "portmeans_cent, portbydate_cent = getCentMeans(portsubin)\n",
    "PMC_factor = portbydate_cent.loc[portbydate_cent['portnum']=='HML'][['Date','logrx']]\n",
    "PMC_factor.rename(columns={'logrx':'PMC'},inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "263ed905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# portsubin = portsubours.copy()\n",
    "# portsubin.sort_values(by=['iso3', 'Date'], inplace=True)\n",
    "# portsubin['prevSumShares'] = portsubin.groupby('iso3')['SumShares'].shift(12)\n",
    "# #portsubin['prevcent'] = portsubin.groupby('iso3')['cent'].shift(12)\n",
    "# portsubin['prevfwdspread'] = portsubin.groupby('iso3')['forwardspread'].shift(1)\n",
    "        \n",
    "# # We want to have risk premia info and the invoicing variable to rank on\n",
    "# portsubin.dropna(subset=['logrx','prevSumShares'], inplace=True)\n",
    "# #portsubin.dropna(subset=['logrx','prevcent'], inplace=True)\n",
    "\n",
    "# # Compute number of countries for which prevSumShares is available at given date\n",
    "# portsubin['count_prevSumShares'] =  portsubin.groupby('Date')['prevSumShares'].transform('count')  \n",
    "# # We want to have at least 4 countries per date (to be able to form 4 portfolios)\n",
    "# portsubin = portsubin.loc[portsubin['count_prevSumShares'] >= 4]\n",
    "    \n",
    "# # sort on last year's invoicing concentration (add one since categories start at 0 otherwise)\n",
    "# portsubin['portnum'] = (1 + portsubin.groupby('year',group_keys=False)['prevSumShares']\n",
    "#                             .apply(GetPortNums,numports=numports)\n",
    "#                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "08864241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# ----| Sort on invoicing currencies |----\n",
    "# ----------------------------------------\n",
    "\n",
    "# Define function computing means by portfolios\n",
    "def getInvoiceMeans(portsubin):\n",
    "    portsubin.sort_values(by=['iso3', 'Date'], inplace=True)\n",
    "    portsubin['prevSumShares'] = portsubin.groupby('iso3')['SumShares'].shift(12)\n",
    "    portsubin['prevfwdspread'] = portsubin.groupby('iso3')['forwardspread'].shift(1)\n",
    "    \n",
    "    # We want to have risk premia info and the invoicing variable to rank on\n",
    "    portsubin.dropna(subset=['logrx','prevSumShares'], inplace=True)\n",
    "    \n",
    "    # Compute number of countries for which prevSumShares is available at given date\n",
    "    portsubin['count_prevSumShares'] =  portsubin.groupby('Date')['prevSumShares'].transform('count')\n",
    "    # We want to have at least 4 countries per date (to be able to form 4 portfolios)\n",
    "    portsubin = portsubin.loc[portsubin['count_prevSumShares'] >= 4].copy()\n",
    "    \n",
    "    # sort on last year's invoicing concentration (add one since categories start at 0 otherwise)\n",
    "    portsubin['portnum'] = (1 + portsubin.groupby('year',group_keys=False)['prevSumShares']\n",
    "                            .apply(GetPortNums,numports=numports)\n",
    "                           )   \n",
    "\n",
    "    # get averages within portfolio at each given date\n",
    "    portbydate = ( portsubin.groupby(by=['Date','portnum'],as_index=False)\n",
    "                  .agg({'logrx':'mean', \n",
    "                        'forwardspread':'mean', \n",
    "                        'realfwdspread':'mean',\n",
    "                        'prevSumShares':['count','mean'], \n",
    "                        'consrs_pwt':'mean'})\n",
    "                 )\n",
    "    portbydate.columns = ['Date','portnum', \n",
    "                         'logrx', 'forwardspread','realfwdspread',\n",
    "                          'numcountries','prevSumShares','conscor']\n",
    "    \n",
    "    # get a high minus low portfolio\n",
    "    # reshape to long form with new 'measure' column\n",
    "    longform = pd.melt(portbydate,id_vars=['Date','portnum'],var_name='measure')\n",
    "    # reshape to wide form but this time with the portfolios in columns\n",
    "    byportfolio = longform.pivot_table(index=['Date','measure'],columns='portnum',values='value').reset_index()\\\n",
    "            .rename_axis(None, axis=1)\n",
    "    # compute returns with various measures of HML portfolio\n",
    "    byportfolio['HML'] = byportfolio[1] - byportfolio[4]\n",
    "    # reshape to long form again, with 'measure' column\n",
    "    tmp = pd.melt(byportfolio, id_vars=['Date','measure'],var_name='portnum')\n",
    "    # reshape to wide form again, with HML being another colum in addition to the numbered portfolios\n",
    "    portbydate = tmp.pivot_table(index=['Date','portnum'],columns='measure',values='value').reset_index()\\\n",
    "            .rename_axis(None, axis=1)\n",
    "    \n",
    "    # get averages within portfolio at each given date\n",
    "    portmeans = ( portbydate.groupby(by=['portnum'],as_index=False)\n",
    "               .agg({'prevSumShares':'mean',\n",
    "                     'numcountries':'mean',\n",
    "                     'logrx':[mean1200,std12],\n",
    "                     'forwardspread':mean1200,\n",
    "                     'realfwdspread':mean1200,\n",
    "                     'conscor':'mean'\n",
    "                    })\n",
    "             )\n",
    "    portmeans.columns = ['portnum', 'prevSumShares', 'numcountries', \n",
    "                         'logrx', 'sdlogrx', 'forwardspread',\n",
    "                         'realfwdspread','conscor']\n",
    "    portmeans['sharperatio'] = portmeans['logrx']/portmeans['sdlogrx']\n",
    "    \n",
    "    return portmeans, portbydate\n",
    "    \n",
    "portsubin = portsubours.copy()\n",
    "portmeans_invoice, portbydate_invoice = getInvoiceMeans(portsubin)\n",
    "DMC_factor = portbydate_invoice.loc[portbydate_invoice['portnum']=='HML'][['Date','logrx']]\n",
    "DMC_factor.rename(columns={'logrx':'DMC'},inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "935f56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# ------| Sort on forward spreads |-------\n",
    "# ----------------------------------------\n",
    "\n",
    "# Define function computing means by portfolios\n",
    "def getFsMeans(portsubin):\n",
    "    # Lag the sorting varaible so that it is feasible\n",
    "    portsubin['prevfwdspread'] = portsubin.groupby('iso3')['forwardspread'].shift(1)\n",
    "    \n",
    "    # We want to have risk premia info and the variable to rank on\n",
    "    portsubin.dropna(subset=['logrx','prevfwdspread'], inplace=True)\n",
    "    \n",
    "    # sort on last month's fwdspread (add one since categories start at 0 otherwise)\n",
    "    portsubin['portnum'] = (1 + portsubin.groupby('Date',group_keys=False)['prevfwdspread']\n",
    "                            .apply(GetPortNums,numports=numports)\n",
    "                           )\n",
    "    \n",
    "    # get averages within portfolio at each given date\n",
    "    portbydate = ( portsubin.groupby(by=['Date','portnum'],as_index=False)\n",
    "                  .agg({'logrx':'mean', \n",
    "                        'prevfwdspread':'mean',\n",
    "                        'forwardspread':'mean', \n",
    "                        'iso3':'count', \n",
    "                        'consrs_pwt':'mean',\n",
    "                        'gdpshare':'mean'})\n",
    "                 )\n",
    "    portbydate.columns = ['Date','portnum', \n",
    "                         'logrx', 'prevfwdspread','fwdspread',\n",
    "                          'numcountries','conscor','gdpshare']\n",
    "    \n",
    "    # get a high minus low portfolio\n",
    "    # reshape to long form with new 'measure' column\n",
    "    longform = pd.melt(portbydate,id_vars=['Date','portnum'],var_name='measure')\n",
    "    # reshape to wide form but this time with the portfolios in columns\n",
    "    byportfolio = longform.pivot_table(index=['Date','measure'],columns='portnum',values='value').reset_index()\\\n",
    "            .rename_axis(None, axis=1)\n",
    "    # compute returns with various measures of HML portfolio\n",
    "    byportfolio['HML'] = byportfolio[4] - byportfolio[1]\n",
    "    # reshape to long form again, with 'measure' column\n",
    "    tmp = pd.melt(byportfolio, id_vars=['Date','measure'],var_name='portnum')\n",
    "    # reshape to wide form again, with HML being another colum in addition to the numbered portfolios\n",
    "    portbydate = tmp.pivot_table(index=['Date','portnum'],columns='measure',values='value').reset_index()\\\n",
    "            .rename_axis(None, axis=1)\n",
    "    \n",
    "    # get time series statistics of the portfolios\n",
    "    portmeans = ( portbydate.groupby(by=['portnum'],as_index=False)\n",
    "               .agg({'numcountries':'mean',\n",
    "                     'logrx':[mean1200,std12],\n",
    "                     'fwdspread':[mean1200,std12],\n",
    "                     'prevfwdspread':[mean1200,std12],\n",
    "                     'conscor':'mean',\n",
    "                     'gdpshare':'mean'})\n",
    "             )\n",
    "    portmeans.columns = ['portnum', 'numcountries', \n",
    "                         'logrx', 'sdlogrx', \n",
    "                         'fwdspread', 'sdfwdspread',\n",
    "                         'prevfwdspread', 'sdprevfwdspread',\n",
    "                         'conscor','gdpshare']\n",
    "    portmeans['sharperatio'] = portmeans['logrx']/portmeans['sdlogrx']\n",
    "    \n",
    "    return portmeans, portbydate\n",
    "\n",
    "portsubin = portsub.copy()\n",
    "portmeans_fs, portbydate_fs = getFsMeans(portsubin)\n",
    "HML_factor = portbydate_fs.loc[portbydate_fs['portnum']=='HML'][['Date','logrx']]\n",
    "HML_factor.rename(columns={'logrx':'HML'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "28677a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# ---| Sort on unconditional spreads |----\n",
    "# ----------------------------------------\n",
    "\n",
    "# Define function computing means by portfolios\n",
    "def getUnconditionalMeans(portsubin):\n",
    "    # We want to have risk premia info and the variable to rank on\n",
    "    portsubin.dropna(subset=['logrx','meanforwardhalf'], inplace=True)\n",
    "    \n",
    "    # sort on meanforwardhalf (add one since categories start at 0 otherwise)\n",
    "    portsubin['portnum'] = (1 + portsubin.groupby('Date',group_keys=False)['meanforwardhalf']\n",
    "                            .apply(GetPortNums,numports=numports)\n",
    "                           )\n",
    "    \n",
    "    # get averages within portfolio at each given date\n",
    "    portbydate = ( portsubin.groupby(by=['Date','portnum'],as_index=False)\n",
    "                  .agg({'logrx':'mean', \n",
    "                        'forwardspread':'mean', \n",
    "                        'meanforwardhalf':'mean',\n",
    "                        'iso3':'count',\n",
    "                        'consrs_pwt':'mean',\n",
    "                        'gdpshare':'mean'})\n",
    "                 )\n",
    "    portbydate.columns = ['Date','portnum', \n",
    "                          'logrx', 'fwdspread','meanforwardfirst',\n",
    "                          'numcountries','conscor','gdpshare']\n",
    "    \n",
    "    # get a high minus low portfolio\n",
    "    # reshape to long form with new 'measure' column\n",
    "    longform = pd.melt(portbydate,id_vars=['Date','portnum'],var_name='measure')\n",
    "    # reshape to wide form but this time with the portfolios in columns\n",
    "    byportfolio = longform.pivot_table(index=['Date','measure'],columns='portnum',values='value').reset_index()\\\n",
    "            .rename_axis(None, axis=1)\n",
    "    # compute returns with various measures of HML portfolio\n",
    "    byportfolio['HML'] = byportfolio[4] - byportfolio[1]\n",
    "    # reshape to long form again, with 'measure' column\n",
    "    tmp = pd.melt(byportfolio, id_vars=['Date','measure'],var_name='portnum')\n",
    "    # reshape to wide form again, with HML being another colum in addition to the numbered portfolios\n",
    "    portbydate = tmp.pivot_table(index=['Date','portnum'],columns='measure',values='value').reset_index()\\\n",
    "            .rename_axis(None, axis=1)\n",
    "    \n",
    "    # get time series statistics of the portfolios\n",
    "    portmeans = ( portbydate.groupby(by=['portnum'],as_index=False)\n",
    "                   .agg({'numcountries':'mean',\n",
    "                     'logrx':[mean1200,std12],\n",
    "                     'fwdspread':mean1200,\n",
    "                     'meanforwardfirst':mean1200,\n",
    "                     'conscor':'mean',\n",
    "                     'gdpshare':'mean'})\n",
    "                )\n",
    "    portmeans.columns = ['portnum', 'numcountries', \n",
    "                         'logrx', 'sdlogrx', \n",
    "                         'fwdspread','meanforwardfirst', \n",
    "                         'conscor','gdpshare']\n",
    "    portmeans['sharperatio'] = portmeans['logrx']/portmeans['sdlogrx']\n",
    "    \n",
    "    return portmeans, portbydate\n",
    "\n",
    "portsinunconditional = portsub.copy()\n",
    "\n",
    "# calculate the mean of f-s for the first half of the sample\n",
    "firsthalfmean = ( portsinunconditional[(portsinunconditional['year'].isin(list(range(1988,2001+1)))) & \n",
    "                                    (portsinunconditional['iso3']!='TUR')]\n",
    "                                    .groupby(by=['iso3'],as_index=False)\n",
    "                                    .agg({'forwardspread':'mean'})\n",
    "                                    .rename(columns={'forwardspread':'meanforwardhalf'})               \n",
    "                 )\n",
    "firsthalfmean.dropna(subset=['meanforwardhalf'], inplace=True)\n",
    "portsinunconditional = pd.merge(left=portsinunconditional,right=firsthalfmean,how='left',on='iso3')\n",
    "\n",
    "# now limit to second half of sample\n",
    "portsinunconditional.drop(portsinunconditional[portsinunconditional['year']<2002].index,\n",
    "                         inplace=True)\n",
    "# drop observations with NaN on meanforwardhalf and logrx columns\n",
    "portsinunconditional.dropna(subset=['meanforwardhalf','logrx'], inplace=True)\n",
    "\n",
    "# compute returns of unconditional high minus low (UHML) \n",
    "portmeans_unconditional, portbydate_unconditional = getUnconditionalMeans(portsinunconditional)\n",
    "UHML_factor = portbydate_unconditional.loc[portbydate_unconditional['portnum']=='HML'][['Date','logrx']]\n",
    "UHML_factor.rename(columns={'logrx':'UHML'},inplace=True)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4d33d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# --| Sort on unconditional centrality |--\n",
    "# ----------------------------------------\n",
    "\n",
    "# generate a ranking\n",
    "portsinunconditionalcent = portsub.copy()\n",
    "portsinunconditionalcent['rank'] = portsinunconditionalcent.groupby(by='Date')['cent'].rank('average')\n",
    "portsinunconditionalcent['maxrank'] = portsinunconditionalcent.groupby(by='Date')['rank'].transform(max)\n",
    "max_n = 39\n",
    "# Division by 1200 is because we use the same function as for unconditional spreads (*1200 in function)\n",
    "portsinunconditionalcent['rank'] = portsinunconditionalcent['rank']/portsinunconditionalcent['maxrank']*max_n\\\n",
    "                                    /1200\n",
    "\n",
    "## calculate the mean of f-s for the first half of the sample\n",
    "firsthalfmeancent = ( portsinunconditionalcent[(portsinunconditionalcent['year'].isin(list(range(1988,2001+1))))]\n",
    "                                    .groupby(by=['iso3'],as_index=False)\n",
    "                                    .agg({'rank':'mean'})\n",
    "                                    .rename(columns={'rank':'meanforwardhalf'})\n",
    "                    )\n",
    "\n",
    "portsinunconditionalcent = pd.merge(left=portsinunconditionalcent,right=firsthalfmeancent,how='left',on='iso3')\n",
    "\n",
    "# now limit to second half of sample\n",
    "portsinunconditionalcent.drop(portsinunconditionalcent[portsinunconditionalcent['year']<2002].index,\n",
    "                         inplace=True)\n",
    "# drop observations with NaN on meanforwardhalf and logrx columns\n",
    "portsinunconditionalcent.dropna(subset=['meanforwardhalf','logrx'], inplace=True)\n",
    "\n",
    "portmeans_unconditionalcent, portbydate_unconditionalcent = getUnconditionalMeans(portsinunconditionalcent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1a680c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the factors together\n",
    "# Richmond replication\n",
    "all_factors = pd.merge(left=PMC_factor,right=HML_factor,how='outer',on='Date')\n",
    "all_factors = pd.merge(left=all_factors,right=UHML_factor,how='outer',on='Date')\n",
    "# Our currency invoicing measure\n",
    "all_factorsours = pd.merge(left=DMC_factor,right=HML_factor,how='outer',on='Date')\n",
    "all_factorsours = pd.merge(left=all_factorsours,right=UHML_factor,how='outer',on='Date')\n",
    "\n",
    "# save\n",
    "all_factors.to_pickle(Factors_FX_Portfolios_Cent)\n",
    "all_factorsours.to_pickle(Factors_FX_Portfolios_Invoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2187aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the log rx for all the ports used\n",
    "# export the sorted portfolios too\n",
    "tmp_ports_fs = portbydate_fs[['Date','portnum','logrx']].copy()\n",
    "tmp_ports_fs['type'] = 'fs'\n",
    "tmp_ports_unconditional = portbydate_unconditional[['Date','portnum','logrx']].copy()\n",
    "tmp_ports_unconditional['type'] = 'unconditional'\n",
    "\n",
    "# Richmond replication\n",
    "all_ports = portbydate_cent[['Date','portnum','logrx']].copy()\n",
    "all_ports['type'] = 'cent'\n",
    "all_ports = pd.concat([all_ports, tmp_ports_fs, tmp_ports_unconditional])\n",
    "#all_ports = pd.concat([all_ports, tmp_ports_unconditional])\n",
    "\n",
    "# Our currency invoicing measure\n",
    "all_portsinv = portbydate_invoice[['Date','portnum','logrx']].copy()\n",
    "all_portsinv['type'] = 'invoice'\n",
    "all_portsinv = pd.concat([all_portsinv, tmp_ports_fs, tmp_ports_unconditional])\n",
    "#all_portsinv = pd.concat([all_portsinv, tmp_ports_unconditional])\n",
    "\n",
    "# save\n",
    "all_ports.to_pickle(PortfolioData_PortfolioRX_AllSorts_Cent)\n",
    "all_portsinv.to_pickle(PortfolioData_PortfolioRX_AllSorts_Invoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "382727f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059.089542865753\n"
     ]
    }
   ],
   "source": [
    "# Boostrap everything\n",
    "def getBootSample(datain,nreps=10000,nblock=240,varlist = ['forwardspread','realfwdspread','logrx']):\n",
    "    \n",
    "    varlistboot = ['Date','portnum']\n",
    "    varlistoutboot = ['portnum']\n",
    "    varlistboot.extend(varlist)\n",
    "    varlistoutboot.extend(varlist)\n",
    "    varlistoutboot.extend(['sharperatio'])\n",
    "\n",
    "    tmp = datain[varlistboot]\n",
    "    #print(tmp)\n",
    "    Outbootsample = pd.DataFrame(columns=varlistoutboot)\n",
    "    \n",
    "    # For loop to generate Outbootsample\n",
    "    for nn in range(nreps):\n",
    "        \n",
    "        # Move to wide form so as to make each date a realization\n",
    "        wideform = ( tmp.pivot_table(index=['Date'],columns=['portnum'],\n",
    "                                               values=varlist)\n",
    "                                    .reset_index()\n",
    "                                    .rename_axis(None, axis=0)\n",
    "                   )\n",
    "        # Sample with replacement\n",
    "        mysample_wide=wideform.sample(n=len(wideform),replace=True,axis=0)\n",
    "        # Put sample back in long form\n",
    "        mysample_long=pd.melt(mysample_wide,id_vars=['Date'],var_name=['measure','portnum'])\n",
    "        # Compute means by portfolios\n",
    "        outmeans = ( mysample_long.groupby(by=['portnum','measure'],as_index=False)\n",
    "                    .agg({'value':mean1200})\n",
    "                   )\n",
    "        \n",
    "        # Compute sharpe ratio by portfolio\n",
    "        outSR = ( mysample_long.groupby(by=['portnum','measure'],as_index=False)\n",
    "                  .agg({'value':SR12})\n",
    "                )\n",
    "        \n",
    "        # Put means and SR in wide format\n",
    "        outmeans_wide = outmeans.pivot_table(index='portnum',columns='measure',values='value').reset_index()\\\n",
    "            .rename_axis(None, axis=1)\n",
    "        outSR_wide = ( outSR.pivot_table(index='portnum',columns='measure',values='value')\n",
    "                        .reset_index()\n",
    "                        .rename_axis(None, axis=1)\n",
    "                        .rename(columns={'logrx':'sharperatio'})\n",
    "                     ) \n",
    "        \n",
    "        outSR_wide = outSR_wide[['portnum','sharperatio']]\n",
    "        \n",
    "        outsample = pd.merge(left=outmeans_wide,right=outSR_wide,on='portnum',how='left')\n",
    "        \n",
    "        Outbootsample = pd.concat([Outbootsample, outsample], ignore_index=True)\n",
    "        \n",
    "    return Outbootsample        \n",
    "        \n",
    "    # leaving out runconscor block for now\n",
    "\n",
    "start_time = time.time()\n",
    "centbootsample = getBootSample(portbydate_cent)\n",
    "invoicebootsample = getBootSample(portbydate_invoice)\n",
    "FSbootsample = getBootSample(portbydate_fs,varlist = ['fwdspread','prevfwdspread','logrx'])\n",
    "Unconditionalbootsample = getBootSample(portbydate_unconditional,varlist = ['fwdspread','logrx'])\n",
    "        \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0e3fc40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind everything together into one dataset\n",
    "\n",
    "centbootsample['sorttype'] = 'cent'\n",
    "invoicebootsample['sorttype'] = 'invoice'\n",
    "FSbootsample['sorttype'] = 'fwdspread'\n",
    "Unconditionalbootsample['sorttype'] = 'unconditional'\n",
    "\n",
    "allboot = pd.concat([centbootsample,invoicebootsample,FSbootsample,Unconditionalbootsample],axis=0,ignore_index=True)\n",
    "\n",
    "# Compute standard deviation of statistics\n",
    "stderrors = ( allboot.groupby(by=['sorttype','portnum'],as_index=False)\n",
    "                 .agg('std')\n",
    "            )\n",
    "\n",
    "# Append _se to all column title\n",
    "stderrors.columns += '_se'\n",
    "stderrors.rename(columns={'sorttype_se':'sorttype','portnum_se':'portnum'},inplace=True)\n",
    "\n",
    "tmplong = portmeans_cent.copy()\n",
    "tmplonginv = portmeans_invoice.copy()\n",
    "tmplongfs = portmeans_fs.copy()\n",
    "tmplongunconditional = portmeans_unconditional.copy()\n",
    "tmplong['sorttype'] = 'cent'\n",
    "tmplonginv['sorttype'] = 'invoice'\n",
    "tmplongfs['sorttype'] = 'fwdspread'\n",
    "tmplongunconditional['sorttype'] = 'unconditional'\n",
    "\n",
    "tmpall = pd.concat([tmplong,tmplonginv,tmplongfs,tmplongunconditional],axis=0,ignore_index=True)\n",
    "portdataout = pd.merge(left=tmpall,right=stderrors,how='left',on=['sorttype','portnum'])\n",
    "# Displace 'sorttype' column to make it first\n",
    "portdataout.insert(0, 'sorttype', portdataout.pop('sorttype'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ec36242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "# (strings defined at beginning of program)\n",
    "portdataout.to_pickle(PortfolioData_AllSorts_BootStrap)\n",
    "centbootsample.to_pickle(PortfolioData_BootStrap_centSort)\n",
    "invoicebootsample.to_pickle(PortfolioData_BootStrap_InvoiceSort)\n",
    "FSbootsample.to_pickle(PortfolioData_BootStrap_FSSort)\n",
    "Unconditionalbootsample.to_pickle(PortfolioData_BootStrap_UnconditionalSort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "451fbd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>DMC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996-09-30</td>\n",
       "      <td>0.031964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1996-10-31</td>\n",
       "      <td>0.023415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1996-11-30</td>\n",
       "      <td>0.008308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1996-12-31</td>\n",
       "      <td>0.021772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1997-01-31</td>\n",
       "      <td>-0.023425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.008149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>-0.005317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>-0.012533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>0.015657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>-0.009912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       DMC\n",
       "4    1996-09-30  0.031964\n",
       "9    1996-10-31  0.023415\n",
       "14   1996-11-30  0.008308\n",
       "19   1996-12-31  0.021772\n",
       "24   1997-01-31 -0.023425\n",
       "...         ...       ...\n",
       "1144 2016-08-31  0.008149\n",
       "1149 2016-09-30 -0.005317\n",
       "1154 2016-10-31 -0.012533\n",
       "1159 2016-11-30  0.015657\n",
       "1164 2016-12-31 -0.009912\n",
       "\n",
       "[233 rows x 2 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DMC_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba0e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
